# API Schema & Discord Commands

This document defines the JSON schema for messages passed between the system's components and the available Discord slash commands.

## 1. Message Schema

The core communication between the `server-bot` and `client-bot` happens via encrypted JSON payloads. This ensures that the content of user prompts and AI responses is kept confidential as it transits through Discord's infrastructure.

### 1.1. Request Payload (`server-bot` -> `client-bot`)

This is the structure of the JSON object that is encrypted and sent by the `server-bot` to request an LLM inference.

```json
{
  "version": "1.0",
  "session_id": "sess_a1b2c3d4e5f67890",
  "request_id": "req_f0e9d8c7b6a54321",
  "timestamp_utc": "2025-09-16T18:30:00Z",
  "prompt": "Translate the following English text to French: 'Hello, world!'",
  "model_parameters": {
    "model_alias": "vicuna-13b-v1.5",
    "temperature": 0.8,
    "top_p": 0.95,
    "max_tokens": 2048
  },
  "metadata": {
    "user_id": "usr_web_98765",
    "discord_channel_id": "112233445566778899"
  }
}
```

-   **`version`**: Schema version to allow for future upgrades.
-   **`session_id`**: Uniquely identifies the chat session.
-   **`request_id`**: Uniquely identifies this specific request-response pair.
-   **`timestamp_utc`**: ISO 8601 timestamp of when the request was generated.
-   **`prompt`**: The full prompt text to be processed by the LLM.
-   **`model_parameters`**:
    -   `model_alias`: A friendly name for the model to be used (e.g., "vicuna-13b", "llama2-70b-chat"). The `client-bot` maps this to a specific model file.
    -   `temperature`, `top_p`, `max_tokens`: Standard LLM sampling parameters.
-   **`metadata`**: Additional context about the request's origin.

### 1.2. Response Payload (`client-bot` -> `server-bot`)

This is the structure of the JSON object that is encrypted and sent back by the `client-bot`.

```json
{
  "version": "1.0",
  "session_id": "sess_a1b2c3d4e5f67890",
  "request_id": "req_f0e9d8c7b6a54321",
  "timestamp_utc": "2025-09-16T18:30:05Z",
  "response": "Bonjour, le monde !",
  "metrics": {
    "tokens_per_second": 45.7,
    "gpu_utilization_percent": 85.2,
    "inference_time_ms": 1250,
    "model_used": "/path/to/models/vicuna-13b-v1.5.gguf"
  },
  "metadata": {
    "client_version": "0.2.1"
  }
}
```

-   **`response`**: The text generated by the LLM.
-   **`metrics`**: Performance data from the `client-bot`.
    -   `tokens_per_second`: The throughput of the model for this request.
    -   `gpu_utilization_percent`: GPU usage during inference.
    -   `inference_time_ms`: Total time taken for the model to generate the response.
    -   `model_used`: The actual file path of the model used for the inference.
-   **`metadata`**: Additional context from the client.

### 1.3. Error Payload (`client-bot` -> `server-bot`)

Used when the `client-bot` encounters an error and cannot fulfill the request.

```json
{
  "version": "1.0",
  "session_id": "sess_a1b2c3d4e5f67890",
  "request_id": "req_f0e9d8c7b6a54321",
  "timestamp_utc": "2025-09-16T18:30:02Z",
  "error": {
    "code": 5001,
    "message": "Model alias 'unknown-model' not found in configuration.",
    "details": "The requested model alias could not be mapped to a local GGUF file."
  }
}
```

-   **`error`**:
    -   `code`: An internal error code for easier debugging.
    -   `message`: A human-readable error message.
    -   `details`: Optional, more specific information about the error.

## 2. Discord Slash Commands

These commands are used to interact with and manage the AI system directly from Discord.

### User Commands

-   **/ai start `[prompt]`**:
    -   Starts a new AI chat session.
    -   Creates a new private channel (e.g., `#ai-session-username-123`).
    -   The optional `prompt` parameter starts the session with an initial message.
    -   **Alias**: `/start`

-   **/ai set-system `[message]`**:
    -   Sets the "system prompt" for the current session.
    -   This allows the user to define the AI's persona or provide context for the entire conversation (e.g., "You are a helpful assistant that always responds in rhyme.").
    -   Must be used inside an active session channel.

-   **/ai set-temp `[value]`**:
    -   Adjusts the temperature for the current session.
    -   `value` must be a number between 0.0 and 2.0.
    -   Must be used inside an active session channel.

-   **/ai end**:
    -   Ends the current chat session.
    -   The bot archives the channel, saves a transcript to S3, and DMs a copy of the transcript to the user.
    -   The channel becomes read-only.
    -   **Alias**: `/end-chat`

### Admin-Only Commands

*(Requires a specific "AI Admin" role in Discord)*

-   **/ai-admin status**:
    -   Displays the current status of the system, including `client-bot` uptime, queue length, and current inference rate.

-   **/ai-admin toggle `[service]`**:
    -   Enables or disables a specific part of the system.
    -   `service`: `requests` (disables new requests), `fallback` (disables the offline fallback model).

-   **/ai-admin transfer `[session_id]` `[new_user]`**:
    -   Transfers control of a chat session to another Discord user.
    -   Useful for shift changes or escalations.

-   **/ai-admin metrics `[timeframe]`**:
    -   Generates and posts a report of system metrics.
    -   `timeframe`: `24h`, `7d`, `30d`.

-   **/ai-admin backup `[target]`**:
    -   Manually triggers a backup.
    -   `target`: `database`, `transcripts`.

-   **/ai-admin reboot `[target]`**:
    -   Sends a command to gracefully reboot a component.
    -   `target`: `client-bot`, `server-bot`.
